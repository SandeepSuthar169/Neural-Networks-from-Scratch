!pip install nnfs

import numpy as np
import nnfs
from nnfs.datasets import spiral_data

nnfs.init()

class Layer_dense:
  def __init__(self, inputs, neurons):
    self.w = 0.01*np.random.randn(inputs, neurons)
    self.b = np.zeros((1, neurons))

  def forward(self, inputs):
    self.output = np.dot(inputs, self.w) + self.b


class Relu:
  def forward(self, inputs):
    self.output = np.maximum(0, inputs)

class Softmax:
  def forward(self, inputs):
    exp = np.exp(inputs - np.max(inputs, axis=1, keepdims =True))

    probabilities = exp/np.sum(exp, axis= 1, keepdims=True)
    self.output = probabilities

class Loss:
  def calculate(self, output, y):
      sample_loss = self.forward(output, y)
      data_loss = np.mean(sample_loss)
      return data_loss

class Catagorical_cross_entropy(Loss):
  def forward(self, y_pred, y_true):   # y_pred -> predicted value
                                         # y_true -> actiual value
      samples = len(y_pred)
      y_pred_clipped = np.clip(y_pred, 1e-7, 1-1e-7)


# pribalility of targey value
      if len(y_true.shape)==1:
         correct_confidences = y_pred_clipped[range(samples), y_true]

#     one-hor encoded lalbels
      elif len(y_true.shape)==2:
          correct_confidences = np.sum(y_pred_clipped * y_true, axis=1)
# losses
      negative_log_likelihoods = -np.log(correct_confidences)
      return negative_log_likelihoods



x, y =spiral_data(samples=100, classes=3)
dense1 = Layer_dense(2, 3)
activation1 = Relu()

dense2 = Layer_dense(3, 3)
activation2  = Softmax()

loss_function = Catagorical_cross_entropy()

lowest_loss = 99999999
best_dense1_w = dense1.w.copy()
best_dense1_b = dense1.b.copy()
best_dense2_w = dense2.w.copy()
best_dense2_b = dense2.b.copy()


# update w with some small random values
for iteration in range(1000):
  dense1.w += 0.05*np.random.randn(2,3)
  dense1.b += 0.05*np.random.randn(1,3)

  dense2.w +=0.05*np.random.randn(3,3)
  dense2.b +=0.05*np.random.randn(1,3)

#
  dense1.forward(x)
  activation1.forward(dense1.output)

  dense2.forward(activation1.output)
  activation2.forward(dense2.output)



  loss = loss_function.calculate(activation2.output, y)
  predictions = np.argmax(activation2.output, axis=1)
  accuracy = np.mean(predictions==y)
  print(iteration, loss, accuracy)



if loss <lowest_loss:
  print(iteration, loss, accuracy)
  best_dense1_w = dense1.w.copy()
  best_dense1_b = dense1.b.copy()
  best_dense2_w = dense2.w.copy()
  best_dense2_b = dense2.b.copy()
  lowest_loss=loss

else:
  dense1.w = best_dense1_w.copy()
  dense1.b = best_dense1_b.copy()
  dense2.w = best_dense2_w.copy()
  dense2.b = best_dense2_b.copy()
